<!doctype html>
<html lang='en'>
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <style>body{ margin:0; background:black }</style>
    <script type="text/javascript" src="build/dat.gui.min.js"></script> 
   
  </head>
  <body>
    <canvas id='gl'></canvas>
  </body>
  
  <!-- vertex shader, as simple as possible -->
  <script id='vertex' type='x-shader/x-vertex'>
    attribute vec2 a_position;

    void main() {
      gl_Position = vec4( a_position, 0, 1 );
    }
  </script>

  <script id='feedback' type='x-shader/x-fragment'>
    #ifdef GL_ES
    precision mediump float;
    #endif
  
    uniform float time;
    uniform float feedbackAmount;
    uniform vec2  resolution;
    
    // for our live video feed
    uniform sampler2D videoTexture;
    // get access to the last frame of video
    uniform sampler2D feedbackTexture;
  
    vec2 fade(vec2 t) {return t*t*t*(t*(t*6.0-15.0)+10.0);}
    vec4 permute(vec4 x){return mod(((x*34.0)+1.0)*x, 289.0);}

    float cnoise(vec2 P){
    vec4 Pi = floor(P.xyxy) + vec4(0.0, 0.0, 1.0, 1.0);
    vec4 Pf = fract(P.xyxy) - vec4(0.0, 0.0, 1.0, 1.0);
    Pi = mod(Pi, 289.0); 
    vec4 ix = Pi.xzxz;
    vec4 iy = Pi.yyww;
    vec4 fx = Pf.xzxz;
    vec4 fy = Pf.yyww;
    vec4 i = permute(permute(ix) + iy);
    vec4 gx = 2.0 * fract(i * 0.0243902439) - 1.0; 
    vec4 gy = abs(gx) - 0.5;
    vec4 tx = floor(gx + 0.5);
    gx = gx - tx;
    vec2 g00 = vec2(gx.x,gy.x);
    vec2 g10 = vec2(gx.y,gy.y);
    vec2 g01 = vec2(gx.z,gy.z);
    vec2 g11 = vec2(gx.w,gy.w);
    vec4 norm = 1.79284291400159 - 0.85373472095314 * 
        vec4(dot(g00, g00), dot(g01, g01), dot(g10, g10), dot(g11, g11));
    g00 *= norm.x;
    g01 *= norm.y;
    g10 *= norm.z;
    g11 *= norm.w;
    float n00 = dot(g00, vec2(fx.x, fy.x));
    float n10 = dot(g10, vec2(fx.y, fy.y));
    float n01 = dot(g01, vec2(fx.z, fy.z));
    float n11 = dot(g11, vec2(fx.w, fy.w));
    vec2 fade_xy = fade(Pf.xy);
    vec2 n_x = mix(vec2(n00, n01), vec2(n10, n11), fade_xy.x);
    float n_xy = mix(n_x.x, n_x.y, fade_xy.y);
    return 2.3 * n_xy;
    }
    void main() {
      vec2 pos = gl_FragCoord.xy / resolution;
      vec3 video = mod(texture2D( videoTexture, pos +cnoise(pos*time/feedbackAmount)).rgb, .9);
      vec3 prior = texture2D( feedbackTexture, pos ).rgb;
      
      // our final output is a combination of the live video signal
      // and our feedback
      gl_FragColor = vec4( (video * .125 + prior * .925), 1. );
    }
  </script>

  <!-- fragment shader -->
  <script id='fragment' type='x-shader/x-fragment'>
    #ifdef GL_ES
    precision mediump float;
    #endif
  
    uniform sampler2D uSampler;
    uniform vec2 resolution;
  
    void main() {
      // copy color info from texture
      gl_FragColor = vec4( texture2D( uSampler, gl_FragCoord.xy / resolution ).rgb, 1. );
    }
  </script>

  
  <script type='text/javascript'>
    // kinda global variables... upvalues to each closure of each function in this script tag
    let gl, uTime, uRes, drawProgram, videoTexture, ui, controls
    

    const size = 768
    window.onload = function() {

      const canvas = document.getElementById( 'gl' )
      gl = canvas.getContext( 'webgl' )
      canvas.width = canvas.height = size
      
      // define drawing area of webgl canvas. bottom corner, width / height
      // XXX can't remember why we need the *2!
      gl.viewport( 0,0,gl.drawingBufferWidth*2, gl.drawingBufferHeight*2 )

      // create a buffer object to store vertices
      const buffer = gl.createBuffer()

      // point buffer at graphic context's ARRAY_BUFFER
      gl.bindBuffer( gl.ARRAY_BUFFER, buffer )

      // create two triangles (three vertices each) that fill entire canvas,
      // with coordinates measured from -1 to 1.
      const triangles = new Float32Array([
        -1, -1,
         1, -1,
        -1,  1,
        -1,  1,
         1, -1,
         1,  1
      ])

      // initialize memory for buffer and populate it. Give
      // open gl hint contents will not change dynamically.
      gl.bufferData( gl.ARRAY_BUFFER, triangles, gl.STATIC_DRAW )

      // create vertex shader
      let shaderScript = document.getElementById('vertex')
      let shaderSource = shaderScript.text
      // create shader object
      const vertexShader = gl.createShader( gl.VERTEX_SHADER )
      // define source text for our shader
      gl.shaderSource( vertexShader, shaderSource )
      // compile shader
      gl.compileShader( vertexShader )

      // create fragment shader
      shaderScript = document.getElementById('fragment')
      shaderSource = shaderScript.text
      const fragmentShader = gl.createShader( gl.FRAGMENT_SHADER )
      gl.shaderSource( fragmentShader, shaderSource )
      gl.compileShader( fragmentShader )

      // create shader program, which links vertex and fragment shaders
      drawProgram = gl.createProgram()
      gl.attachShader( drawProgram, vertexShader )
      gl.attachShader( drawProgram, fragmentShader )
      // report any errors in the fragment shader
      console.log( gl.getShaderInfoLog( fragmentShader ) )
      gl.linkProgram( drawProgram )
      gl.useProgram( drawProgram )
      

      /* ALL ATTRIBUTE/UNIFORM INITIALIZATION MUST COME AFTER 
      CREATING/LINKING/USING THE SHADER PROGAM */
      
      // find a pointer to the uniform "time" in our fragment shader
      uTime = gl.getUniformLocation( drawProgram, 'time' ) 
      uRes = gl.getUniformLocation( drawProgram, 'resolution' )
      // send uniform values for uRes up to gpu
      gl.uniform2f( uRes, size, size )

      // get position attribute location in shader
      var position = gl.getAttribLocation( drawProgram, 'a_position' )
      // enable the attribute
      gl.enableVertexAttribArray( position )
      // this will point to the vertices in the last bound array buffer.
      // In this example, we only use one array buffer, where we're storing 
      // our vertices
      gl.vertexAttribPointer( position, 2, gl.FLOAT, false, 0,0 )

        //define another shader program for swapping
      shaderScript = document.getElementById('feedback')
        shaderSource = shaderScript.text
        const feedbackFragmentShader = gl.createShader( gl.FRAGMENT_SHADER )
        gl.shaderSource( feedbackFragmentShader, shaderSource )
        gl.compileShader( feedbackFragmentShader )
        console.log( gl.getShaderInfoLog( feedbackFragmentShader ) )

        // create feedback shader program
        feedbackProgram = gl.createProgram()
        gl.attachShader( feedbackProgram, vertexShader )
        gl.attachShader( feedbackProgram, feedbackFragmentShader )

        gl.linkProgram( feedbackProgram )
        gl.useProgram( feedbackProgram )

        uRes = gl.getUniformLocation( feedbackProgram, 'resolution' )
        gl.uniform2f( uRes, gl.drawingBufferWidth, gl.drawingBufferHeight )
        
        uFeedback = gl.getUniformLocation( feedbackProgram, 'feedbackAmount' )
        

        // find a pointer to the uniform "time" in our fragment shader
        uTime = gl.getUniformLocation( feedbackProgram, 'time' )

        // one texture for feedback, one for video. There will actually be
        // a third texture involved, but we'll only need to access two in our
        // feedback shader in any given frame of video.
        uFeedbackTexture = gl.getUniformLocation( feedbackProgram, 'feedbackTexture' )
        uVideoTexture = gl.getUniformLocation( feedbackProgram, 'videoTexture' )

        position = gl.getAttribLocation( feedbackProgram, 'a_position' )
        gl.enableVertexAttribArray( feedbackProgram )
        gl.vertexAttribPointer( position, 2, gl.FLOAT, false, 0,0 )

        controls = function() {
             this.feedback = 10;
             // Define render logic ...
        };

        ui = new controls();
        var gui = new dat.GUI();
        gui.add(ui, 'feedback', 0, 100);

        gl.uniform1f( uFeedback, ui.feedback )
        // gui.add(text, 'speed', -5, 5);
        // gui.add(text, 'displayOutline');
        // gui.add(text, 'explode');
      
      video = getVideo()
    }
    
    function getVideo() {
      const video = document.createElement('video');

      // request video stream
      navigator.mediaDevices.getUserMedia({
        video:true
      }).then( stream => { 
        // this block happens when the video stream has been successfully requested
        video.srcObject = stream
        video.play()
        makeTexture()
      }) 
        
      return video
    }
    
    function makeTexture() {
      // create an OpenGL texture object
      videoTexture = gl.createTexture()
      
      // this tells OpenGL which texture object to use for subsequent operations
      gl.bindTexture( gl.TEXTURE_2D, videoTexture )
        
      // since canvas draws from the top and shaders draw from the bottom, we
      // have to flip our canvas when using it as a shader.
      gl.pixelStorei(gl.UNPACK_FLIP_Y_WEBGL, true);

      // how to map when texture element is more than one pixel
      gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MAG_FILTER, gl.LINEAR )
      // how to map when texture element is less than one pixel
      gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MIN_FILTER, gl.LINEAR )
      
      // you must have these properties defined for the video texture to
      // work correctly at non-power-of-2 sizes
      gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_S, gl.CLAMP_TO_EDGE )
      gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_T, gl.CLAMP_TO_EDGE )

      textureBack = gl.createTexture()
        gl.bindTexture( gl.TEXTURE_2D, textureBack )
        gl.texParameteri( gl.TEXTURE_2D, gl.TEXTURE_WRAP_S, gl.CLAMP_TO_EDGE )
        gl.texParameteri( gl.TEXTURE_2D, gl.TEXTURE_WRAP_T, gl.CLAMP_TO_EDGE )
        gl.texParameteri( gl.TEXTURE_2D, gl.TEXTURE_MIN_FILTER, gl.LINEAR )
        gl.texParameteri( gl.TEXTURE_2D, gl.TEXTURE_MAG_FILTER, gl.LINEAR )
        gl.texImage2D( gl.TEXTURE_2D, 0, gl.RGBA, size, size, 0, gl.RGBA, gl.UNSIGNED_BYTE, null )

        textureFront = gl.createTexture()
        gl.bindTexture( gl.TEXTURE_2D, textureFront )
        gl.texParameteri( gl.TEXTURE_2D, gl.TEXTURE_WRAP_S, gl.CLAMP_TO_EDGE )
        gl.texParameteri( gl.TEXTURE_2D, gl.TEXTURE_WRAP_T, gl.CLAMP_TO_EDGE )
        gl.texParameteri( gl.TEXTURE_2D, gl.TEXTURE_MIN_FILTER, gl.LINEAR )
        gl.texParameteri( gl.TEXTURE_2D, gl.TEXTURE_MAG_FILTER, gl.LINEAR )
        gl.texImage2D( gl.TEXTURE_2D, 0, gl.RGBA, size, size, 0, gl.RGBA, gl.UNSIGNED_BYTE, null )

        // Create a framebuffer and attach the texture.
        framebuffer = gl.createFramebuffer()
      
      render()
    }

    // keep track of time via incremental frame counter
        let time = 0
    function render() {
        // schedules render to be called the next time the video card requests 
        // a frame of video
        window.requestAnimationFrame( render )
        
        // use our feedback shader
        gl.useProgram( feedbackProgram )  
        // update time on CPU and GPU
        time++
        gl.uniform1f( uTime, time )     
        gl.bindFramebuffer( gl.FRAMEBUFFER, framebuffer )
        // use the framebuffer to write to our texFront texture
        gl.framebufferTexture2D( gl.FRAMEBUFFER, gl.COLOR_ATTACHMENT0, gl.TEXTURE_2D, textureFront, 0 )
        // this defines the size of the data that will be drawn onto our texture
        gl.viewport(0, 0, size,size )
        
        gl.activeTexture( gl.TEXTURE0 )
        gl.bindTexture( gl.TEXTURE_2D, videoTexture )
        gl.uniform1i( uVideoTexture, 0 )
        gl.texImage2D( 
            gl.TEXTURE_2D,    // target: you will always want gl.TEXTURE_2D
            0,                // level of detail: 0 is the base
            gl.RGBA, gl.RGBA, // color formats
            gl.UNSIGNED_BYTE, // type: the type of texture data; 0-255
            video             // pixel source: could also be video or image
    )

        // in our shaders, read from texBack, which is where we poked to
        gl.activeTexture( gl.TEXTURE1 )
        gl.bindTexture( gl.TEXTURE_2D, textureBack )
        gl.uniform1i( uFeedbackTexture, 1 )
        gl.uniform1f( uFeedback, ui.feedback)
        // run shader
        gl.drawArrays( gl.TRIANGLES, 0, 6 )

        // swap our front and back textures
        let tmp = textureFront
        textureFront = textureBack
        textureBack = tmp

        // use the default framebuffer object by passing null
        gl.bindFramebuffer( gl.FRAMEBUFFER, null )
        gl.viewport(0, 0, size, size )
        // select the texture we would like to draw to the screen.
        // note that webgl does not allow you to write to / read from the
        // same texture in a single render pass. Because of the swap, we're
        // displaying the state of our simulation ****before**** this render pass (frame)
        gl.activeTexture( gl.TEXTURE0 )
        gl.bindTexture( gl.TEXTURE_2D, textureFront )
        // use our drawing (copy) shader
        gl.useProgram( drawProgram )
        // put simulation on screen
        gl.drawArrays( gl.TRIANGLES, 0, 6 )

        //uFeedback += ui.feedback;
    }
  </script>

</html>